{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aborbala/tree-canopy/blob/main/calculate_priors_from_yolo_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cltfVJ_wT1np",
        "outputId": "1b3cb72d-6744-40b9-b42d-f3c958d0309a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwhey96NTz6v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "274sYYKmTuQy",
        "outputId": "c8cb478e-e97e-493e-dafb-aa6b97645b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 536 label files. Analyzing polygon areas...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing labels: 100%|██████████| 536/536 [01:11<00:00,  7.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Calculation Complete ---\n",
            "Foreground Classes specified: [1]\n",
            "Foreground (Tree) Prior (pi_1): 0.130932\n",
            "Background Prior (pi_0): 0.869068\n",
            "\n",
            ">>> IMPORTANT: Update these values in your loss.py file! <<<\n",
            "Example update in v8SegmentationLoss.__init__:\n",
            "    background_prior = 0.869068\n",
            "    foreground_prior = 0.130932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "label_dir = \"/content/drive/MyDrive/masterthesis/data/386_5818/yolo_dataset_no_structures_veg_mask/labels/train\"\n",
        "\n",
        "foreground_classes = [1]\n",
        "\n",
        "def polygon_area(x, y):\n",
        "    \"\"\"\n",
        "    Calculates the area of a polygon using the Shoelace formula.\n",
        "    Args:\n",
        "        x (list): A list of x-coordinates of the polygon's vertices.\n",
        "        y (list): A list of y-coordinates of the polygon's vertices.\n",
        "    Returns:\n",
        "        float: The area of the polygon.\n",
        "    \"\"\"\n",
        "    # The coordinates are assumed to be in order around the polygon.\n",
        "    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n",
        "\n",
        "def calculate_priors(label_path, fg_classes):\n",
        "    \"\"\"\n",
        "    Calculates the total foreground area and image count for a YOLO dataset.\n",
        "    \"\"\"\n",
        "    total_foreground_area_normalized = 0.0\n",
        "\n",
        "    label_files = [f for f in os.listdir(label_path) if f.endswith('.txt')]\n",
        "    if not label_files:\n",
        "        raise FileNotFoundError(f\"No .txt label files found in '{label_path}'. Please check the path.\")\n",
        "\n",
        "    num_images = len(label_files)\n",
        "\n",
        "    print(f\"Found {num_images} label files. Analyzing polygon areas...\")\n",
        "\n",
        "    for label_file in tqdm(label_files, desc=\"Processing labels\"):\n",
        "        with open(os.path.join(label_path, label_file), 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if not parts:\n",
        "                    continue\n",
        "\n",
        "                class_id = int(parts[0])\n",
        "\n",
        "                # Check if the class is one of our foreground classes\n",
        "                if class_id in fg_classes:\n",
        "                    coords = np.array(list(map(float, parts[1:])))\n",
        "                    x_coords = coords[0::2] # All even indices are x\n",
        "                    y_coords = coords[1::2] # All odd indices are y\n",
        "\n",
        "                    area = polygon_area(x_coords, y_coords)\n",
        "                    total_foreground_area_normalized += area\n",
        "\n",
        "    if num_images == 0:\n",
        "        return 0.0, 0.0\n",
        "\n",
        "    # The total normalized area is simply the number of images (since each has a normalized area of 1.0)\n",
        "    # The average foreground proportion is the total foreground area divided by the total area.\n",
        "    pi_foreground = total_foreground_area_normalized / num_images\n",
        "    pi_background = 1.0 - pi_foreground\n",
        "\n",
        "    return pi_background, pi_foreground\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gflRr7PoVZKu",
        "outputId": "ac0eb27c-34ec-4197-b841-af297e3ae486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 536 label files. Analyzing polygon areas...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing labels: 100%|██████████| 536/536 [00:05<00:00, 94.54it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Calculation Complete ---\n",
            "Foreground Classes specified: [0, 1]\n",
            "Foreground (Tree) Prior (pi_1): 0.225960\n",
            "Background Prior (pi_0): 0.774040\n",
            "\n",
            ">>> IMPORTANT: Update these values in your loss.py file! <<<\n",
            "Example update in v8SegmentationLoss.__init__:\n",
            "    background_prior = 0.774040\n",
            "    foreground_prior = 0.225960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "pi_background, pi_foreground = calculate_priors(label_dir, [0,1])\n",
        "\n",
        "print(\"\\n--- Calculation Complete ---\")\n",
        "print(f\"Foreground Classes specified: {[0,1]}\")\n",
        "print(f\"Foreground (Tree) Prior (pi_1): {pi_foreground:.6f}\")\n",
        "print(f\"Background Prior (pi_0): {pi_background:.6f}\")\n",
        "print(\"\\n>>> IMPORTANT: Update these values in your loss.py file! <<<\")\n",
        "print(\"Example update in v8SegmentationLoss.__init__:\")\n",
        "print(f\"    background_prior = {pi_background:.6f}\")\n",
        "print(f\"    foreground_prior = {pi_foreground:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DjtxiIGSSIl",
        "outputId": "1d4b6ac3-7aaf-4f7c-dfc9-56f107a195a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 'train' split with 536 images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Analyzing train labels: 100%|██████████| 536/536 [00:12<00:00, 41.63it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 'val' split with 135 images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Analyzing val labels: 100%|██████████| 135/135 [00:02<00:00, 61.62it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "--- Dataset Polygon Count Summary ---\n",
            "             Total Polygons  Class 0 Polygons  Class 1 Polygons\n",
            "train                  7641              4032              3609\n",
            "val                    1993              1092               901\n",
            "Grand Total            9634              5124              4510\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def analyze_dataset_counts(base_label_dir: str):\n",
        "    \"\"\"\n",
        "    Iterates through train and val label directories of a YOLO dataset to count polygons.\n",
        "\n",
        "    The function provides a breakdown of total polygons and counts for each class\n",
        "    for both the training and validation splits, plus an overall total.\n",
        "\n",
        "    Args:\n",
        "        base_label_dir (str): The path to the base 'labels' directory, which should\n",
        "                              contain 'train' and 'val' subdirectories.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A DataFrame summarizing the polygon counts for each\n",
        "                          class and data split.\n",
        "    \"\"\"\n",
        "    splits_to_process = ['train', 'val']\n",
        "\n",
        "    # Use defaultdict to gracefully handle any class ID, even if not 0 or 1\n",
        "    counts = {split: defaultdict(int) for split in splits_to_process}\n",
        "\n",
        "    # Iterate through each split (train, val)\n",
        "    for split in splits_to_process:\n",
        "        split_path = os.path.join(base_label_dir, split)\n",
        "\n",
        "        if not os.path.isdir(split_path):\n",
        "            print(f\"Warning: Directory not found for split '{split}': {split_path}\")\n",
        "            continue\n",
        "\n",
        "        label_files = [f for f in os.listdir(split_path) if f.endswith('.txt')]\n",
        "        print(f\"\\nProcessing '{split}' split with {len(label_files)} images...\")\n",
        "\n",
        "        # Iterate through each label file in the current split\n",
        "        for label_file in tqdm(label_files, desc=f\"Analyzing {split} labels\"):\n",
        "            with open(os.path.join(split_path, label_file), 'r') as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if not parts:\n",
        "                        continue\n",
        "\n",
        "                    # Each line in a YOLO label file represents one polygon/object\n",
        "                    counts[split]['Total Polygons'] += 1\n",
        "\n",
        "                    try:\n",
        "                        class_id = int(parts[0])\n",
        "                        counts[split][f'Class {class_id} Polygons'] += 1\n",
        "                    except (ValueError, IndexError):\n",
        "                        print(f\"Warning: Could not parse line in {label_file}: {line.strip()}\")\n",
        "\n",
        "    # Convert the nested dictionary to a pandas DataFrame and fill any missing values with 0\n",
        "    summary_df = pd.DataFrame.from_dict(counts, orient='index').fillna(0).astype(int)\n",
        "\n",
        "    if summary_df.empty:\n",
        "        print(\"\\nNo data processed. Cannot create summary.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Calculate a 'Grand Total' row\n",
        "    summary_df.loc['Grand Total'] = summary_df.sum()\n",
        "\n",
        "    # Ensure columns are in a logical order (Total first, then sorted class columns)\n",
        "    class_cols = sorted([col for col in summary_df.columns if 'Class' in col])\n",
        "    other_cols = [col for col in summary_df.columns if 'Class' not in col]\n",
        "    summary_df = summary_df[other_cols + class_cols]\n",
        "\n",
        "    return summary_df\n",
        "\n",
        "\n",
        "base_label_dir = \"/content/drive/MyDrive/masterthesis/data/386_5818/yolo_dataset_no_structures_veg_mask/labels\"\n",
        "\n",
        "# Run the analysis\n",
        "dataset_summary = analyze_dataset_counts(base_label_dir)\n",
        "\n",
        "# Print the final summary table\n",
        "print(\"\\n\\n--- Dataset Polygon Count Summary ---\")\n",
        "print(dataset_summary.to_string())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPo0xpafPdOlLnJFCaSzt7H",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
